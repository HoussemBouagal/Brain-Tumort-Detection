import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping

# Chemin du dataset
dataset_path = "E:\\Brain Tumor MRI Dataset\\Train"
test_dataset_path = "E:\\Brain Tumor MRI Dataset\\Test"

# V√©rification des chemins
def check_path(path):
    if not os.path.exists(path):
        raise FileNotFoundError(f"‚ö†Ô∏è Chemin introuvable: {path}. Assurez-vous que le dataset est extrait!")
check_path(dataset_path)
check_path(test_dataset_path)

# Param√®tres
taille_image = (224, 224)
taille_batch = 32
taux_apprentissage = 0.0001

# G√©n√©rateur de donn√©es avec augmentation
datagen = ImageDataGenerator(
    rescale=1./255, 
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode="nearest",
    validation_split=0.2  # 20% des donn√©es pour validation
)

# Chargement des donn√©es d'entra√Ænement et validation
train_data = datagen.flow_from_directory(
    dataset_path,
    target_size=taille_image,
    batch_size=taille_batch,
    class_mode='categorical',
    subset="training"
)
val_data = datagen.flow_from_directory(
    dataset_path,
    target_size=taille_image,
    batch_size=taille_batch,
    class_mode='categorical',
    subset="validation"
)

# Chargement des donn√©es de test
test_data = datagen.flow_from_directory(
    test_dataset_path,
    target_size=taille_image,
    batch_size=taille_batch,
    class_mode='categorical',
    shuffle=False
)

# R√©cup√©ration des classes
class_names = list(train_data.class_indices.keys())
print(f"üìå Classes disponibles: {class_names}")

# Mod√®le MobileNetV2 (Transfer Learning)
base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False  # On g√®le les couches pr√©-entra√Æn√©es

# Construction du mod√®le
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    BatchNormalization(),
    Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    Dropout(0.5),
    Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    Dropout(0.3),
    Dense(len(class_names), activation='softmax')
])

# Compilation du mod√®le
model.compile(
    optimizer=Adam(learning_rate=taux_apprentissage),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Affichage du r√©sum√© du mod√®le
model.summary()

# Callbacks pour l'optimisation
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Entra√Ænement du mod√®le
epochs = 25
history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=epochs,
    callbacks=[lr_scheduler, early_stopping]
)

# Sauvegarde du mod√®le
model_path = os.path.join(os.getcwd(), "brain_tumor_model.keras")
model.save(model_path)
print(f"‚úÖ Mod√®le sauvegard√© avec succ√®s √†: {model_path}")

# Fonction de visualisation
def plot_metrics(history):
    plt.figure(figsize=(12, 5))

    # Pr√©cision
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Entra√Ænement')
    plt.plot(history.history['val_accuracy'], label='Validation')
    plt.xlabel('√âpochs')
    plt.ylabel('Pr√©cision')
    plt.legend()
    plt.title('üìä Progression de la pr√©cision')

    # Perte
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Entra√Ænement')
    plt.plot(history.history['val_loss'], label='Validation')
    plt.xlabel('√âpochs')
    plt.ylabel('Perte')
    plt.legend()
    plt.title('üìâ Progression de la perte')

    plt.show()

plot_metrics(history)

# √âvaluation sur les donn√©es de test
test_loss, test_acc = model.evaluate(test_data)
print(f"üìä Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}")
# Affichage de l'accuracy finale apr√®s entra√Ænement
final_train_acc = history.history['accuracy'][-1]
final_val_acc = history.history['val_accuracy'][-1]
print(f"‚úÖ Accuracy finale - Entra√Ænement: {final_train_acc:.4f}, Validation: {final_val_acc:.4f}")